<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://eric-mb.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://eric-mb.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-06-19T07:57:54+00:00</updated><id>https://eric-mb.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Best Paper Award at ICMR 2024</title><link href="https://eric-mb.github.io/news/2024/icmr2024/" rel="alternate" type="text/html" title="Best Paper Award at ICMR 2024" /><published>2024-06-11T00:00:00+00:00</published><updated>2024-06-11T00:00:00+00:00</updated><id>https://eric-mb.github.io/news/2024/icmr2024</id><content type="html" xml:base="https://eric-mb.github.io/news/2024/icmr2024/"><![CDATA[<p>We are thrilled to announce that we received the <em>*Best Paper Award” at the *International Conference on Multimedia Retrieval (ICMR) 2024</em> in Phuket, Thailand.</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Presented our interdisciplinary research on &quot;Identification of Speaker Roles and Situation Types in News Videos&quot; in the best paper session @ <a href="https://twitter.com/hashtag/ICMR2024?src=hash&amp;ref_src=twsrc%5Etfw">#ICMR2024</a> in Phuket, Thailand. In the context of narrativization in news media.<a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> <a href="https://twitter.com/hashtag/NewsAnalytics?src=hash&amp;ref_src=twsrc%5Etfw">#NewsAnalytics</a> <a href="https://twitter.com/hashtag/Multimodal?src=hash&amp;ref_src=twsrc%5Etfw">#Multimodal</a> <a href="https://twitter.com/hashtag/FakeNarratives?src=hash&amp;ref_src=twsrc%5Etfw">#FakeNarratives</a> <a href="https://t.co/AanXn7Apzl">pic.twitter.com/AanXn7Apzl</a></p>&mdash; Gullal S. Cheema (@Gullal7) <a href="https://twitter.com/Gullal7/status/1800480377582322121?ref_src=twsrc%5Etfw">June 11, 2024</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>]]></content><author><name></name></author><summary type="html"><![CDATA[We are thrilled to announce that we received the *Best Paper Award” at the *International Conference on Multimedia Retrieval (ICMR) 2024 in Phuket, Thailand.]]></summary></entry><entry><title type="html">Two papers presented at SCSMI 2024</title><link href="https://eric-mb.github.io/news/2024/scsmi2024/" rel="alternate" type="text/html" title="Two papers presented at SCSMI 2024" /><published>2024-06-06T00:00:00+00:00</published><updated>2024-06-06T00:00:00+00:00</updated><id>https://eric-mb.github.io/news/2024/scsmi2024</id><content type="html" xml:base="https://eric-mb.github.io/news/2024/scsmi2024/"><![CDATA[<p>We presented our progress in the projects <a href="https://service.tib.eu/tibava/"><strong>TIB-AV-A</strong></a> and <a href="https://fakenarratives.github.io/"><strong>FakeNarratives</strong></a> in two presentations at the <em>Society for Cognitive Studies of the Moving Image Conference (SCSMI) 2024</em> in Budapest, Hungary. It was nice meeting film scholars to further develop our approaches for film and news analysis.</p>

<blockquote>
  <p><strong>Eric Müller-Budack</strong>, Matthias Springstein, Margret Plank, Julian Sittel, Roman Mauer, Oksana Bulgakowa, Manuel Burghardt, John Bateman, Ralph Ewerth (2024). TIB AV Analytics: A Computational Tool for Film and Video Analysis. <em>Society for Cognitive Studies of the Moving Image Conference, SCSMI, Budapest, Hungary, June 5-8, 2024.</em></p>
  <h4 id="abstract">Abstract</h4>
  <p>In this presentation, we provide an overview of current computational tools and methods for film and video analysis. After briefly contextualizing this direction of development against the evolution of methods in this field, we set out theoretical foundations for empirical video analyses that are fully responsive to the nature of film as an expressive medium. As we focus on using state-of-the-art information extraction methods (typically based on deep learning), we also provide an overview of the types of information that can already be extracted with these methods. Specifically, we introduce a web-based tool for systematic film and video analysis, called TIB AV-Analytics (TIB-AV-A). We show the wide range of analysis methods provided by TIB-AV-A and demonstrate how it can be used to support video analysis. Finally, we conclude by summarizing the current state of available tools and methods for computational video analysis and outline some challenges that lie ahead.</p>
</blockquote>

<blockquote>
  <p>Chiao-I Tseng, John A. Bateman, Leandra Thiele, Ralph Ewerth, <strong>Eric Müller-Budack</strong>, Gullal Cheema, Manuel Burghardt, Bernhard Liebl (2024). The search for filmic narrative strategies in audiovisual news reporting: a progress report. <em>Society for Cognitive Studies of the Moving Image Conference, SCSMI, Budapest, Hungary, June 5-8, 2024.</em></p>
  <h4 id="abstract-1">Abstract</h4>
  <p>Audiovisual news reporting is now documented to involve many filmic techniques that bring news reporting ever closer to audiovisual storytelling. At SCSMI-2022 we introduced our FakeNarratives project, which undertakes a contrastive cataloguing of filmic narrative strategies in both mainstream and alternative news media to support the location of potentially problematic messaging. We now discuss the progress that has been made towards automating the recognition of filmic structures using diverse computational techniques for audiovisual processing. Results are maintained in a searchable richly annotated graph structure, allowing us to define narrative patterns in terms of formal combinations of filmic features present in the graph. By these means, we increase the scale of data on which filmic narrative patterns can be derived, empirically validated, and productively visualised. As the analytic framework is oriented to audiovisual material in general, we also show how aspects of the account may contribute to film research more broadly.</p>
</blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[We presented our progress in the projects TIB-AV-A and FakeNarratives in two presentations at the Society for Cognitive Studies of the Moving Image Conference (SCSMI) 2024 in Budapest, Hungary. It was nice meeting film scholars to further develop our approaches for film and news analysis.]]></summary></entry><entry><title type="html">Journal Article on Understanding Semantic Image-Text Relations</title><link href="https://eric-mb.github.io/news/2023/frontiers-paper/" rel="alternate" type="text/html" title="Journal Article on Understanding Semantic Image-Text Relations" /><published>2023-05-02T00:00:00+00:00</published><updated>2023-05-02T00:00:00+00:00</updated><id>https://eric-mb.github.io/news/2023/frontiers-paper</id><content type="html" xml:base="https://eric-mb.github.io/news/2023/frontiers-paper/"><![CDATA[<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New journal article on understanding semantic image-text relations and news values for multimodal news analysis. <a href="https://t.co/ymlGvTYOuj">https://t.co/ymlGvTYOuj</a><br /><br />Paper with <a href="https://twitter.com/_ericmb?ref_src=twsrc%5Etfw">@_ericmb</a> <a href="https://twitter.com/chro___?ref_src=twsrc%5Etfw">@chro___</a> <a href="https://twitter.com/SherzodHakimov?ref_src=twsrc%5Etfw">@sherzodhakimov</a> <a href="https://twitter.com/RalphEwerth?ref_src=twsrc%5Etfw">@RalphEwerth</a> &amp; John A Bateman</p>&mdash; Gullal S. Cheema (@Gullal7) <a href="https://twitter.com/Gullal7/status/1653317249027956737?ref_src=twsrc%5Etfw">May 2, 2023</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>]]></content><author><name></name></author><summary type="html"><![CDATA[New journal article on understanding semantic image-text relations and news values for multimodal news analysis. https://t.co/ymlGvTYOujPaper with @_ericmb @chro___ @sherzodhakimov @RalphEwerth &amp; John A Bateman&mdash; Gullal S. Cheema (@Gullal7) May 2, 2023]]></summary></entry><entry><title type="html">PhD Thesis Published</title><link href="https://eric-mb.github.io/news/2022/phd_publication/" rel="alternate" type="text/html" title="PhD Thesis Published" /><published>2022-02-03T00:00:00+00:00</published><updated>2022-02-03T00:00:00+00:00</updated><id>https://eric-mb.github.io/news/2022/phd_publication</id><content type="html" xml:base="https://eric-mb.github.io/news/2022/phd_publication/"><![CDATA[<p>My PhD thesis got published in the institutional repository of the <em>Leibniz Universität Hannover</em>:</p>

<blockquote>
  <p>Müller-Budack, E. (2022). Unsupervised quantification of entity consistency between photos and text in real-world news (p. 222) [Gottfried Wilhelm Leibniz Universität Hannover]. <a href="https://doi.org/https://doi.org/10.15488/11719">Link</a></p>
</blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[My PhD thesis got published in the institutional repository of the Leibniz Universität Hannover:]]></summary></entry><entry><title type="html">FakeNarratives Project Meeting</title><link href="https://eric-mb.github.io/news/2022/fakenarratives_meeting/" rel="alternate" type="text/html" title="FakeNarratives Project Meeting" /><published>2022-02-01T00:00:00+00:00</published><updated>2022-02-01T00:00:00+00:00</updated><id>https://eric-mb.github.io/news/2022/fakenarratives_meeting</id><content type="html" xml:base="https://eric-mb.github.io/news/2022/fakenarratives_meeting/"><![CDATA[<p>The first <em>FakeNarratives</em> project meeting took place virtually on February 1, 2022.</p>

<p><em>FakeNarratives</em> is a joint project with the University of Bremen and the University of Leipzig funded by the <em>Federal Ministry of Education and Research (BMBF)</em>. The core idea of the project is to analyse the narrative structures of disinformation in videos from public and alternative media shared on social networks. More information can be found on our <a href="https://fakenarratives.github.io">project homepage</a>.</p>

<p><img src="/assets/img/foto-kickoff.png" alt="Kickoff Meeting FakeNarratives" width="100%" /></p>]]></content><author><name></name></author><summary type="html"><![CDATA[The first FakeNarratives project meeting took place virtually on February 1, 2022.]]></summary></entry><entry><title type="html">Two Papers at WACV’22</title><link href="https://eric-mb.github.io/news/2022/wacv22/" rel="alternate" type="text/html" title="Two Papers at WACV’22" /><published>2022-01-04T00:00:00+00:00</published><updated>2022-01-04T00:00:00+00:00</updated><id>https://eric-mb.github.io/news/2022/wacv22</id><content type="html" xml:base="https://eric-mb.github.io/news/2022/wacv22/"><![CDATA[<p>We are happy to present two papers at the <em>IEEE Winter Conference on Applications of Computer Vision (WACV) 2022</em> that takes place in Waikoloa, Hawaii from January 4-8, 2022.</p>

<blockquote>
  <p>Theiner, J., Müller-Budack, E., &amp; Ewerth, R. (2022). Interpretable Semantic Photo Geolocation. IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022, Waikoloa, HI, USA, January 3-8, 2022, 1474–1484. <a href="https://doi.org/10.1109/WACV51458.2022.00154">Link</a></p>
</blockquote>

<blockquote>
  <p>Theiner, J., Gritz, W., Müller-Budack, E., Rein, R., Memmert, D., &amp; Ewerth, R. (2022). Extraction of Positional Player Data from Broadcast Soccer Videos. IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022, Waikoloa, HI, USA, January 3-8, 2022, 1463–1473. <a href="https://doi.org/10.1109/WACV51458.2022.00153">Link</a></p>
</blockquote>

<p><img src="/assets/img/WACV_Hawaii_2022.jpg" alt="Banner of WACV 2022 in Hawaii" width="100%" /></p>]]></content><author><name></name></author><summary type="html"><![CDATA[We are happy to present two papers at the IEEE Winter Conference on Applications of Computer Vision (WACV) 2022 that takes place in Waikoloa, Hawaii from January 4-8, 2022.]]></summary></entry><entry><title type="html">PhD Defense</title><link href="https://eric-mb.github.io/news/2021/phd_defense/" rel="alternate" type="text/html" title="PhD Defense" /><published>2021-12-10T00:00:00+00:00</published><updated>2021-12-10T00:00:00+00:00</updated><id>https://eric-mb.github.io/news/2021/phd_defense</id><content type="html" xml:base="https://eric-mb.github.io/news/2021/phd_defense/"><![CDATA[<p>I successfully defended my PhD thesis entitled <a href="https://www.repo.uni-hannover.de/handle/123456789/11812"><em>Unsupervised quantification of entity consistency between photos and text in real-world news</em></a>.</p>

<p>My deepest gratitude goes to the defense committee, especially to my supervisor Prof. Ralph Ewerth, as well as to my friends, colleagues, and family who supported me during my PhD.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I successfully defended my PhD thesis entitled Unsupervised quantification of entity consistency between photos and text in real-world news.]]></summary></entry></feed>